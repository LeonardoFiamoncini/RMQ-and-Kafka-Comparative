# üéì Benchmark Comparativo para TCC

**Trabalho de Conclus√£o de Curso (TCC) - Bacharelado em Ci√™ncia da Computa√ß√£o**

Este projeto implementa um sistema completo de benchmark comparativo entre **RabbitMQ**, **Apache Kafka** e **HTTP S√≠ncrono**, desenvolvido para an√°lise de performance, toler√¢ncia a falhas e escalabilidade de sistemas de mensageria. O sistema foi projetado seguindo rigorosos padr√µes acad√™micos e de engenharia de software.

## üìã √çndice

1. [Vis√£o Geral do Projeto](#-vis√£o-geral-do-projeto)
2. [Pr√©-requisitos do Sistema](#-pr√©-requisitos-do-sistema)
3. [Instala√ß√£o Completa](#-instala√ß√£o-completa)
4. [Configura√ß√£o do Ambiente](#-configura√ß√£o-do-ambiente)
5. [Execu√ß√£o de Todos os Testes](#-execu√ß√£o-de-todos-os-testes)
6. [An√°lise e Visualiza√ß√£o dos Resultados](#-an√°lise-e-visualiza√ß√£o-dos-resultados)
7. [Interpreta√ß√£o dos Resultados](#-interpreta√ß√£o-dos-resultados)
8. [Solu√ß√£o de Problemas](#-solu√ß√£o-de-problemas)
9. [Documenta√ß√£o T√©cnica](#-documenta√ß√£o-t√©cnica)

---

## üéØ Vis√£o Geral do Projeto

### Objetivos Acad√™micos
- **Compara√ß√£o Quantitativa**: An√°lise estat√≠stica de performance entre RabbitMQ, Kafka e HTTP
- **Toler√¢ncia a Falhas**: Avalia√ß√£o de recupera√ß√£o e disponibilidade em cen√°rios de falha
- **Escalabilidade**: Teste de comportamento com m√∫ltiplos clientes concorrentes
- **Reprodutibilidade**: Metodologia cient√≠fica rigorosa para replica√ß√£o dos resultados

### üî¨ Garantia de Reprodutibilidade Total

Este projeto foi desenvolvido com **foco total em reprodutibilidade cient√≠fica**, garantindo que os resultados possam ser replicados em **qualquer hardware e sistema operacional**:

‚úÖ **Vers√µes Fixas e Obrigat√≥rias**:
- RabbitMQ: `4.1.1` (imagem: `rabbitmq:4.1.1-management`)
- Apache Kafka: `4.0.0` (imagem: `apache/kafka:4.0.0`)
- Python: `3.12+` (com vers√µes fixas em `requirements.txt`)

‚úÖ **Configura√ß√µes Padronizadas**:
- Arquivo `docker-compose.yml` com vers√µes fixas
- Configura√ß√£o KRaft em `config/kraft-server.properties`
- Cluster IDs fixos para consist√™ncia

‚úÖ **Ambiente Containerizado**:
- Docker e Docker Compose para isolamento completo
- Scripts de setup automatizados (`scripts/setup_dev_environment.sh`)
- Compatibilidade multi-plataforma (Linux, macOS, Windows/WSL2)

‚úÖ **Documenta√ß√£o Completa**:
- Instru√ß√µes detalhadas para cada sistema operacional
- Troubleshooting para problemas comuns
- Exemplos de execu√ß√£o e an√°lise

### Tecnologias Implementadas
- **RabbitMQ 4.1.1** (imagem: `rabbitmq:4.1.1-management`): Com Quorum Queues e cluster de 3 n√≥s
- **Apache Kafka 4.0** (imagem: `apache/kafka:4.0.0`): Com KRaft mode e Queue Mode (KIP-932)
- **HTTP S√≠ncrono**: Baseline para compara√ß√£o de lat√™ncia (Flask)
- **Docker**: Containeriza√ß√£o completa da infraestrutura
- **Python 3.12+**: Implementa√ß√£o dos clientes e orquestra√ß√£o
- **Kafdrop 3.30.0**: Interface web para monitoramento do Kafka

### M√©tricas Coletadas
- **Lat√™ncia End-to-End**: Tempo total de envio at√© processamento
- **Throughput**: Mensagens processadas por segundo
- **Taxa de Sucesso**: Percentual de entrega garantida
- **Uso de Recursos**: CPU e mem√≥ria dos brokers
- **Tempo de Recupera√ß√£o**: Ap√≥s falhas simuladas

---

## üñ•Ô∏è Pr√©-requisitos do Sistema

### Especifica√ß√µes M√≠nimas
- **Sistema Operacional**: 
  - **Linux**: Ubuntu 22.04 LTS ou superior, Debian 11+, Fedora 36+, ou qualquer distribui√ß√£o com suporte a Docker
  - **macOS**: macOS 11 (Big Sur) ou superior
  - **Windows**: Windows 10/11 com WSL2 ou Docker Desktop
- **RAM**: M√≠nimo 4GB (recomendado 8GB)
- **CPU**: M√≠nimo 2 cores (recomendado 4 cores)
- **Armazenamento**: M√≠nimo 10GB livres
- **Rede**: Conex√£o com internet para download de depend√™ncias

### Software Necess√°rio
- **Docker**: Vers√£o 20.10 ou superior
- **Docker Compose**: Vers√£o 2.0 ou superior (plugin ou standalone)
- **Python**: Vers√£o 3.10 ou superior (3.12 recomendado)
- **Git**: Para clonagem do reposit√≥rio
- **Curl**: Para testes de conectividade
- **Bash**: Para execu√ß√£o dos scripts de setup (Linux/macOS) ou Git Bash/WSL (Windows)

### Verifica√ß√£o dos Pr√©-requisitos

#### Linux (Ubuntu/Debian/Fedora)
```bash
# Verificar vers√£o do sistema
lsb_release -a 2>/dev/null || cat /etc/os-release

# Verificar RAM dispon√≠vel
free -h

# Verificar CPU
lscpu | grep "CPU(s):"

# Verificar espa√ßo em disco
df -h

# Verificar Docker
docker --version
docker compose version

# Verificar Python
python3 --version
pip3 --version
```

#### macOS
```bash
# Verificar vers√£o do macOS
sw_vers

# Verificar RAM dispon√≠vel
sysctl hw.memsize | awk '{print $2/1024/1024/1024 " GB"}'

# Verificar CPU
sysctl -n hw.ncpu

# Verificar espa√ßo em disco
df -h

# Verificar Docker
docker --version
docker compose version

# Verificar Python
python3 --version
pip3 --version
```

#### Windows (WSL2 ou Docker Desktop)
```powershell
# No PowerShell ou WSL
# Verificar vers√£o do Windows
systeminfo | findstr /B /C:"OS Name" /C:"OS Version"

# Verificar Docker
docker --version
docker compose version

# Verificar Python (no WSL)
python3 --version
pip3 --version
```

---

## üöÄ Instala√ß√£o Completa

### Passo 1: Clonagem do Reposit√≥rio
```bash
# Clonar o reposit√≥rio
git clone <URL_DO_REPOSITORIO>
cd RMQ-and-Kafka-Comparative

# Verificar estrutura do projeto
ls -la
```

### Passo 2: Configura√ß√£o Autom√°tica do Ambiente

**Compatibilidade Multi-OS**: O script `setup_dev_environment.sh` funciona em Linux e macOS. Para Windows, use WSL2 ou Docker Desktop.

#### Linux/macOS
```bash
# Dar permiss√µes de execu√ß√£o
chmod +x scripts/setup_dev_environment.sh

# Executar configura√ß√£o autom√°tica
./scripts/setup_dev_environment.sh
```

#### Windows (WSL2)
```bash
# No terminal WSL2
chmod +x scripts/setup_dev_environment.sh
./scripts/setup_dev_environment.sh
```

#### Windows (Docker Desktop)
```powershell
# Instalar Docker Desktop manualmente:
# https://www.docker.com/products/docker-desktop

# No PowerShell ou WSL2, instalar Python e depend√™ncias:
python -m venv venv
.\venv\Scripts\activate  # PowerShell
# ou
source venv/bin/activate  # WSL2

pip install -r requirements.txt
```

**‚ö†Ô∏è IMPORTANTE**: Durante a execu√ß√£o do script:
- Digite sua senha quando solicitado (Linux/macOS)
- Aguarde a instala√ß√£o do Docker (pode demorar alguns minutos)
- **REINICIE O TERMINAL** ap√≥s a conclus√£o para aplicar permiss√µes do Docker (Linux)

### Passo 3: Verifica√ß√£o da Instala√ß√£o
```bash
# Verificar se o usu√°rio est√° no grupo docker
groups | grep docker

# Se n√£o aparecer "docker", reinicie o terminal e tente novamente

# Ativar ambiente virtual
source venv/bin/activate

# Verificar instala√ß√£o das depend√™ncias
pip list | grep -E -i "(flask|werkzeug|pika|kafka-python|requests|matplotlib|seaborn|pandas|numpy|scipy|black|isort|flake8|pytest)"
```

### Passo 4: Inicializa√ß√£o da Infraestrutura
```bash
# Iniciar todos os servi√ßos
docker compose up -d

# Aguardar inicializa√ß√£o (30-60 segundos)
sleep 60

# Verificar status dos containers
docker compose ps
```

**Resultado esperado**: Todos os containers devem estar com status "Up"

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### Verifica√ß√£o dos Servi√ßos

#### 1. RabbitMQ Cluster (3 n√≥s)
```bash
# Verificar cluster RabbitMQ
docker exec rabbitmq-1 rabbitmqctl cluster_status

# Verificar filas
docker exec rabbitmq-1 rabbitmqctl list_queues

# Acessar interface web
echo "RabbitMQ Management: http://localhost:15672"
echo "Usu√°rio: user | Senha: password"
```

#### 2. Apache Kafka
```bash
# Verificar t√≥picos Kafka
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# Verificar brokers
docker exec kafka kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# Acessar interface web
echo "Kafdrop: http://localhost:9000"
```

#### 3. Teste de Conectividade
```bash
# Testar RabbitMQ
curl -u user:password http://localhost:15672/api/overview

# Testar Kafka (via Kafdrop)
curl -s http://localhost:9000 | grep -i kafdrop

# Testar baseline HTTP (ser√° iniciado nos testes)
```

---

## üß™ Execu√ß√£o de Todos os Testes

### üìã Par√¢metros de Entrada (Obrigat√≥rios)

Para garantir medi√ß√µes assertivas, o sistema utiliza par√¢metros espec√≠ficos passados via linha de comando:

#### **a) N√∫mero de Mensagens (`--count`)**
- **Valores v√°lidos**: `5`, `10`, `15`, `100`, `1000`, `10000`, `100000`
- **Descri√ß√£o**: Quantidade total de mensagens a serem enviadas e processadas

#### **b) N√∫mero de Produtores (`--producers`)**
- **Valores v√°lidos**: `1`, `4`, `16`, `64`
- **Descri√ß√£o**: N√∫mero de clientes/produtores simult√¢neos enviando mensagens

#### **c) N√∫mero de Consumidores (`--consumers`)**
- **Valores v√°lidos**: `4`, `64`
- **Descri√ß√£o**: N√∫mero de consumidores processando mensagens da fila

#### **d) Sistema (`--system`)**
- **Valores v√°lidos**: `rabbitmq`, `kafka`, `baseline`
- **Descri√ß√£o**: Sistema de mensageria a ser testado

#### **Par√¢metros Opcionais**
- `--size`: Tamanho de cada mensagem em bytes (padr√£o: 200)
- `--rps`: Rate Limiting - mensagens por segundo (opcional)

### üìä M√©tricas de Sa√≠da Coletadas

O sistema coleta e exibe as seguintes m√©tricas:

#### **i) T (Tempo de Perman√™ncia na Fila)**
- **Defini√ß√£o**: Lat√™ncia m√©dia de uma mensagem desde o envio at√© o processamento
- **Unidade**: Segundos (com precis√£o de microssegundos)
- **Arquivo**: `logs/<system>/<run_id>/*_latency.csv`

#### **ii) V (Throughput / Vaz√£o)**
- **Defini√ß√£o**: N√∫mero de mensagens processadas por unidade de tempo
- **Unidade**: Mensagens por segundo
- **C√°lculo**: `V = mensagens_processadas / dura√ß√£o_total`

> üí° **Importante:** Cada execu√ß√£o gera um identificador exclusivo `run_id`
> (por exemplo, `kafka-1732070501-a1b2c3`) e salva todos os arquivos dessa
> execu√ß√£o em `logs/<system>/<run_id>/`. O arquivo consolidado
> `benchmark_results.csv` continua em `logs/<system>/`.

### üìù Exemplos de Uso

#### **Exemplo 1: Teste Comparativo Justo - Porte Pequeno (100 RPS)**
```bash
# Testar os 3 sistemas com MESMOS par√¢metros para compara√ß√£o justa
python main.py --server --port 5000 &
sleep 3
python main.py --count 100 --producers 1 --consumers 4 --system baseline --rps 100
pkill -f "python main.py --server"

python main.py --count 100 --producers 1 --consumers 4 --system rabbitmq --rps 100
python main.py --count 100 --producers 1 --consumers 4 --system kafka --rps 100
```

#### **Exemplo 2: Teste Comparativo Justo - Porte M√©dio (1.000 RPS)**
```bash
# Testar os 3 sistemas com MESMOS par√¢metros
python main.py --server --port 5000 &
sleep 3
python main.py --count 1000 --producers 4 --consumers 4 --system baseline --rps 1000
pkill -f "python main.py --server"

python main.py --count 1000 --producers 4 --consumers 4 --system rabbitmq --rps 1000
python main.py --count 1000 --producers 4 --consumers 4 --system kafka --rps 1000
```

#### **Exemplo 3: Teste Comparativo Justo - Porte Grande (10.000 RPS)**
```bash
# Testar os 3 sistemas com MESMOS par√¢metros
python main.py --server --port 5000 &
sleep 3
python main.py --count 10000 --producers 16 --consumers 64 --system baseline --rps 10000
pkill -f "python main.py --server"

python main.py --count 10000 --producers 16 --consumers 64 --system rabbitmq --rps 10000
python main.py --count 10000 --producers 16 --consumers 64 --system kafka --rps 10000
```

#### **Exemplo 4: Teste de Chaos Engineering**
```bash
python main.py --chaos --count 5 --size 100 --system rabbitmq
```

#### **Exemplo 5: Gerar Gr√°ficos Comparativos**
```bash
python generate_plots.py --system all
```

### ‚ö†Ô∏è Prepara√ß√£o Importante

**ANTES de executar qualquer teste, execute estes comandos:**

```bash
# 1. Ativar ambiente virtual
source venv/bin/activate

# 2. Verificar se containers est√£o rodando
docker compose ps

# 3. Se n√£o estiverem, iniciar
docker compose up -d
sleep 60

# 4. Limpar logs antigos (IMPORTANTE!)
./scripts/clear_logs.sh

# 5. Verificar conectividade
echo "Testando RabbitMQ..."
curl -u user:password http://localhost:15672/api/overview | head -1

echo "Testando Kafka..."
curl -s http://localhost:9000 | grep -i kafdrop | head -1
```

### üéØ Metodologia de Compara√ß√£o Justa

**IMPORTANTE**: Para uma compara√ß√£o cient√≠fica v√°lida, os tr√™s sistemas (Baseline, RabbitMQ, Kafka) s√£o testados com **EXATAMENTE OS MESMOS PAR√ÇMETROS** em cada porte. Isso garante que as diferen√ßas de performance sejam atribu√≠das √†s tecnologias, n√£o a configura√ß√µes diferentes.

#### Portes Definidos

| Porte | RPS | Mensagens | Produtores | Consumidores | Caracteriza√ß√£o |
|-------|-----|-----------|------------|--------------|----------------|
| **Pequeno** | 100 | 100 | 1 | 4 | Aplica√ß√µes corporativas internas, MVPs |
| **M√©dio** | 1.000 | 1.000 | 4 | 4 | Plataformas de com√©rcio eletr√¥nico estabelecidas |
| **Grande** | 10.000 | 10.000 | 16 | 64 | Servi√ßos globais, redes sociais, mercados financeiros |

**Propor√ß√£o geom√©trica**: 1:10:100 (fundamentada em Jain, 1991)

### Estrutura dos Testes

O sistema executa **testes comparativos justos por porte** e **testes adicionais de recursos**:

#### **Testes Comparativos por Porte (Compara√ß√£o Justa)**
1. **Porte Pequeno (100 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros
2. **Porte M√©dio (1.000 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros
3. **Porte Grande (10.000 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros

#### **Testes Adicionais de Recursos**
4. **Chaos Engineering**: Toler√¢ncia a falhas
5. **Rate Limiting**: Valida√ß√£o de controle de taxa
6. **Monitoramento**: Coleta de m√©tricas de recursos
7. **Visualiza√ß√£o**: Gera√ß√£o de gr√°ficos comparativos

### Execu√ß√£o de Testes Comparativos Justos

#### **TESTE COMPARATIVO: Porte Pequeno (100 RPS)**

**Par√¢metros id√™nticos para os 3 sistemas**: 100 mensagens, 1 produtor, 4 consumidores, RPS=100

```bash
# Ativar ambiente virtual
source venv/bin/activate

# Baseline - Pequeno Porte
python main.py --server --port 5000 &
sleep 3
python main.py --count 100 --producers 1 --consumers 4 --system baseline --rps 100
pkill -f "python main.py --server"

# RabbitMQ - Pequeno Porte (MESMOS PAR√ÇMETROS)
python main.py --count 100 --producers 1 --consumers 4 --system rabbitmq --rps 100

# Kafka - Pequeno Porte (MESMOS PAR√ÇMETROS)
python main.py --count 100 --producers 1 --consumers 4 --system kafka --rps 100
```

**‚úÖ Crit√©rio de Sucesso**: Compara√ß√£o justa com mesmos par√¢metros permite identificar qual tecnologia tem melhor performance.

#### **TESTE COMPARATIVO: Porte M√©dio (1.000 RPS)**

**Par√¢metros id√™nticos para os 3 sistemas**: 1.000 mensagens, 4 produtores, 4 consumidores, RPS=1000

```bash
# Baseline - M√©dio Porte
python main.py --server --port 5000 &
sleep 3
python main.py --count 1000 --producers 4 --consumers 4 --system baseline --rps 1000
pkill -f "python main.py --server"

# RabbitMQ - M√©dio Porte (MESMOS PAR√ÇMETROS)
python main.py --count 1000 --producers 4 --consumers 4 --system rabbitmq --rps 1000

# Kafka - M√©dio Porte (MESMOS PAR√ÇMETROS)
python main.py --count 1000 --producers 4 --consumers 4 --system kafka --rps 1000
```

#### **TESTE COMPARATIVO: Porte Grande (10.000 RPS)**

**Par√¢metros id√™nticos para os 3 sistemas**: 10.000 mensagens, 16 produtores, 64 consumidores, RPS=10000

```bash
# Baseline - Grande Porte
python main.py --server --port 5000 &
sleep 3
python main.py --count 10000 --producers 16 --consumers 64 --system baseline --rps 10000
pkill -f "python main.py --server"

# RabbitMQ - Grande Porte (MESMOS PAR√ÇMETROS)
python main.py --count 10000 --producers 16 --consumers 64 --system rabbitmq --rps 10000

# Kafka - Grande Porte (MESMOS PAR√ÇMETROS)
python main.py --count 10000 --producers 16 --consumers 64 --system kafka --rps 10000
```

**‚úÖ Crit√©rio de Sucesso**: Compara√ß√£o justa permite identificar qual tecnologia escala melhor em alta carga.

#### **TESTE ADICIONAL: Chaos Engineering (Toler√¢ncia a Falhas)**

```bash
# Teste Chaos Engineering - RabbitMQ
echo "=== TESTE: Chaos Engineering - RabbitMQ ==="
python main.py --chaos --count 5 --size 100 --system rabbitmq

# Aguardar recupera√ß√£o
sleep 30

# Teste Chaos Engineering - Kafka
echo "=== TESTE: Chaos Engineering - Kafka ==="
python main.py --chaos --count 5 --size 100 --system kafka

# Aguardar recupera√ß√£o
sleep 30
```

**‚úÖ Crit√©rio de Sucesso**: Sistema deve se recuperar automaticamente ap√≥s falhas.

#### **TESTE ADICIONAL: Gera√ß√£o de Gr√°ficos Comparativos**

```bash
# Gerar todos os gr√°ficos comparativos
echo "=== TESTE: Gera√ß√£o de Gr√°ficos ==="
python generate_plots.py --system all
```

**‚úÖ Crit√©rio de Sucesso**: Gr√°ficos devem ser gerados em `logs/plots/` com compara√ß√µes visuais entre os sistemas.

### Script de Execu√ß√£o Autom√°tica - Testes Comparativos Justos

Para executar todos os testes comparativos justos automaticamente:

```bash
# Executar script de testes comparativos por porte
./test_comparativo_justo_por_porte.sh
```

Este script executa:
1. **Porte Pequeno (100 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros
2. **Porte M√©dio (1.000 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros
3. **Porte Grande (10.000 RPS)**: Baseline, RabbitMQ, Kafka com mesmos par√¢metros
4. **Chaos Engineering**: Testes de toler√¢ncia a falhas
5. **Gera√ß√£o de Gr√°ficos**: Gr√°ficos comparativos autom√°ticos

**‚úÖ Vantagem**: Compara√ß√£o cient√≠fica justa com mesmos par√¢metros permite identificar qual tecnologia tem melhor performance em cada porte.

---

## üìä An√°lise e Visualiza√ß√£o dos Resultados

### Estrutura dos Logs Gerados

```
logs/
‚îú‚îÄ‚îÄ baseline/
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
‚îÇ   ‚îî‚îÄ‚îÄ <run_id>/
‚îÇ       ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
‚îÇ       ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
‚îÇ       ‚îî‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
‚îÇ   ‚îî‚îÄ‚îÄ <run_id>/
‚îÇ       ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
‚îÇ       ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
‚îÇ       ‚îú‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
‚îÇ       ‚îî‚îÄ‚îÄ resource_monitoring.csv        # Monitoramento de recursos
‚îî‚îÄ‚îÄ rabbitmq/
    ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
    ‚îî‚îÄ‚îÄ <run_id>/
        ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
        ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
        ‚îú‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
        ‚îî‚îÄ‚îÄ resource_monitoring.csv        # Monitoramento de recursos
```

### An√°lise dos Resultados

#### 1. Visualiza√ß√£o dos Resultados Consolidados
```bash
# Ver resultados consolidados de cada broker
# O arquivo benchmark_results.csv cont√©m todas as execu√ß√µes com as m√©tricas T e V
echo "=== RESULTADOS BASELINE ==="
echo "Colunas: timestamp, tech, messages, message_size, num_producers, num_consumers, rps, latency_avg (T), latency_50, latency_95, latency_99, throughput (V), successful_producers, successful_consumers"
cat logs/baseline/benchmark_results.csv

echo "=== RESULTADOS RABBITMQ ==="
cat logs/rabbitmq/benchmark_results.csv

echo "=== RESULTADOS KAFKA ==="
cat logs/kafka/benchmark_results.csv
```

#### 2. An√°lise de Lat√™ncia (T - Tempo de Perman√™ncia na Fila)
```bash
# Analisar lat√™ncias mais recentes
# Cada arquivo cont√©m: msg_id, latency_seconds (T)
echo "=== LAT√äNCIAS BASELINE (T) ==="
ls -la logs/baseline/*latency.csv | tail -1 | xargs cat | head -20

echo "=== LAT√äNCIAS RABBITMQ (T) ==="
ls -la logs/rabbitmq/*latency.csv | tail -1 | xargs cat | head -20

echo "=== LAT√äNCIAS KAFKA (T) ==="
ls -la logs/kafka/*latency.csv | tail -1 | xargs cat | head -20

# Calcular estat√≠sticas de lat√™ncia
echo "=== ESTAT√çSTICAS DE LAT√äNCIA ==="
for system in baseline rabbitmq kafka; do
    echo "--- $system ---"
    latest=$(ls -la logs/$system/*latency.csv 2>/dev/null | tail -1 | awk '{print $NF}')
    if [ -n "$latest" ]; then
        awk -F',' 'NR>1 {sum+=$2; count++; if(count==1 || $2<min) min=$2; if($2>max) max=$2} END {if(count>0) print "M√©dia (T): " sum/count "s | Min: " min "s | Max: " max "s | Total: " count}' "$latest"
    fi
done
```

#### 3. An√°lise de Throughput (V - Vaz√£o)
```bash
# Extrair throughput dos summaries e dos resultados consolidados
# V (Throughput) = mensagens por segundo
echo "=== THROUGHPUT BASELINE (V) ==="
ls -la logs/baseline/*summary.csv | tail -1 | xargs grep "throughput_msgs_per_sec"

echo "=== THROUGHPUT RABBITMQ (V) ==="
ls -la logs/rabbitmq/*summary.csv | tail -1 | xargs grep "throughput_msgs_per_sec"

echo "=== THROUGHPUT KAFKA (V) ==="
ls -la logs/kafka/*summary.csv | tail -1 | xargs grep "throughput_msgs_per_sec"

# Extrair throughput dos resultados consolidados (√∫ltima linha)
echo "=== THROUGHPUT DOS RESULTADOS CONSOLIDADOS ==="
for system in baseline rabbitmq kafka; do
    echo "--- $system ---"
    if [ -f "logs/$system/benchmark_results.csv" ]; then
        tail -1 "logs/$system/benchmark_results.csv" | awk -F',' '{print "Throughput (V): " $12 " mensagens/segundo"}'
    fi
done
```

#### 4. Monitoramento de Recursos
```bash
# Verificar monitoramento de recursos
echo "=== RECURSOS RABBITMQ ==="
ls -la logs/rabbitmq/*resource_monitoring.csv | tail -1 | xargs head -10

echo "=== RECURSOS KAFKA ==="
ls -la logs/kafka/*resource_monitoring.csv | tail -1 | xargs head -10
```

### Visualiza√ß√£o Gr√°fica Autom√°tica

O sistema gera **automaticamente gr√°ficos comparativos** ap√≥s cada execu√ß√£o de benchmark. Os gr√°ficos s√£o salvos em `logs/plots/`.

#### Gera√ß√£o Autom√°tica

Os gr√°ficos s√£o gerados **automaticamente** ap√≥s cada execu√ß√£o de benchmark. N√£o √© necess√°rio executar comandos adicionais.

#### Gera√ß√£o Manual de Gr√°ficos

Para gerar gr√°ficos manualmente ou atualizar gr√°ficos existentes:

```bash
# Gerar todos os gr√°ficos dispon√≠veis
python generate_plots.py --system all

# Gerar gr√°ficos de um sistema espec√≠fico
python generate_plots.py --system rabbitmq
python generate_plots.py --system kafka
python generate_plots.py --system baseline

# Gerar gr√°ficos de uma execu√ß√£o espec√≠fica
python generate_plots.py --system rabbitmq --run-id rabbitmq-1763656609-ee18d8
```

#### Tipos de Gr√°ficos Gerados

1. **Compara√ß√£o de Lat√™ncia**: Compara lat√™ncia m√©dia (T) entre sistemas
2. **Compara√ß√£o de Throughput**: Compara throughput (V) entre sistemas
3. **Resumo Comparativo**: Gr√°fico completo com m√∫ltiplas m√©tricas (T, V, percentis)
4. **Distribui√ß√£o de Lat√™ncias**: Histograma de lat√™ncias por sistema

**Localiza√ß√£o**: Todos os gr√°ficos s√£o salvos em `logs/plots/`

**Depend√™ncias**: As bibliotecas de visualiza√ß√£o (matplotlib==3.10.7, seaborn==0.13.2, pandas==2.3.3, numpy==2.3.5, scipy==1.16.3) j√° est√£o inclu√≠das no `requirements.txt` e s√£o instaladas automaticamente.

---

## üìà Interpreta√ß√£o dos Resultados

### M√©tricas Principais

#### 1. **T (Tempo de Perman√™ncia na Fila) - Lat√™ncia**
- **Defini√ß√£o**: Tempo m√©dio que uma mensagem permanece na fila desde o envio at√© o processamento
- **Unidade**: Segundos (com precis√£o de microssegundos)
- **Valores Esperados**:
  - **Baseline HTTP**: 0.001-0.010s
  - **RabbitMQ**: 0.001-0.005s
  - **Apache Kafka**: 0.001-0.003s
- **Arquivo**: `logs/<system>/<run_id>/*_latency.csv` (coluna `latency_seconds`)

#### 2. **V (Throughput / Vaz√£o)**
- **Defini√ß√£o**: N√∫mero de mensagens processadas por unidade de tempo
- **Unidade**: Mensagens por segundo
- **C√°lculo**: `V = mensagens_processadas / dura√ß√£o_total`
- **Valores Esperados**:
  - **Baseline HTTP**: 50-200 msgs/s
  - **RabbitMQ**: 1,000-5,000 msgs/s
  - **Apache Kafka**: 5,000-20,000 msgs/s
- **Arquivo**: `logs/<system>/*_summary.csv` (m√©trica `throughput_msgs_per_sec`) e `benchmark_results.csv` (coluna `throughput`)

#### 3. **Taxa de Sucesso (%)**
- **Todos os brokers**: Esperado 95-100%

#### 4. **Uso de Recursos**
- **CPU**: Varia conforme carga
- **Mem√≥ria**: RabbitMQ ~200MB, Kafka ~300MB

### An√°lise Comparativa

#### Cen√°rio 1: Teste Comparativo Justo - Porte Pequeno (100 RPS)
```bash
# Executar teste comparativo justo (MESMOS par√¢metros para os 3 sistemas)
python main.py --server --port 5000 &
sleep 3
python main.py --count 100 --producers 1 --consumers 4 --system baseline --rps 100
pkill -f "python main.py --server"

python main.py --count 100 --producers 1 --consumers 4 --system rabbitmq --rps 100
python main.py --count 100 --producers 1 --consumers 4 --system kafka --rps 100

# Analisar resultados
echo "=== COMPARA√á√ÉO JUSTA - PORTE PEQUENO (100 RPS) ==="
echo "Baseline - T (Lat√™ncia): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "RabbitMQ - T (Lat√™ncia): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "Kafka    - T (Lat√™ncia): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f12) msgs/s"
```

#### Cen√°rio 2: Teste Comparativo Justo - Porte M√©dio (1.000 RPS)
```bash
# Executar teste comparativo justo (MESMOS par√¢metros para os 3 sistemas)
python main.py --server --port 5000 &
sleep 3
python main.py --count 1000 --producers 4 --consumers 4 --system baseline --rps 1000
pkill -f "python main.py --server"

python main.py --count 1000 --producers 4 --consumers 4 --system rabbitmq --rps 1000
python main.py --count 1000 --producers 4 --consumers 4 --system kafka --rps 1000

# Analisar resultados
echo "=== COMPARA√á√ÉO JUSTA - PORTE M√âDIO (1.000 RPS) ==="
echo "Baseline - T (Lat√™ncia): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "RabbitMQ - T (Lat√™ncia): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "Kafka    - T (Lat√™ncia): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f12) msgs/s"
```

#### Cen√°rio 3: Teste Comparativo Justo - Porte Grande (10.000 RPS)
```bash
# Executar teste comparativo justo (MESMOS par√¢metros para os 3 sistemas)
python main.py --server --port 5000 &
sleep 3
python main.py --count 10000 --producers 16 --consumers 64 --system baseline --rps 10000
pkill -f "python main.py --server"

python main.py --count 10000 --producers 16 --consumers 64 --system rabbitmq --rps 10000
python main.py --count 10000 --producers 16 --consumers 64 --system kafka --rps 10000

# Analisar resultados
echo "=== COMPARA√á√ÉO JUSTA - PORTE GRANDE (10.000 RPS) ==="
echo "Baseline - T (Lat√™ncia): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "RabbitMQ - T (Lat√™ncia): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f12) msgs/s"
echo "Kafka    - T (Lat√™ncia): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f8) segundos | V (Throughput): $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f12) msgs/s"
```

### Relat√≥rio de An√°lise

#### Gerar Relat√≥rio Autom√°tico
```bash
# Criar script de relat√≥rio
cat > gerar_relatorio.py << 'EOF'
#!/usr/bin/env python3
import pandas as pd
import glob
import os
from datetime import datetime

def gerar_relatorio():
    """Gerar relat√≥rio completo dos resultados"""
    
    print("üìä RELAT√ìRIO DE AN√ÅLISE DE PERFORMANCE")
    print("=" * 50)
    print(f"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Analisar cada broker
    brokers = ['baseline', 'rabbitmq', 'kafka']
    
    for broker in brokers:
        print(f"üîç AN√ÅLISE DO {broker.upper()}")
        print("-" * 30)
        
        # Carregar dados
        try:
            data = pd.read_csv(f'logs/{broker}/benchmark_results.csv')
            
            # Estat√≠sticas b√°sicas
            print(f"Total de testes: {len(data)}")
            print(f"V (Throughput m√©dio): {data['throughput'].mean():.2f} mensagens/segundo")
            print(f"T (Lat√™ncia m√©dia): {data['latency_avg'].mean():.6f} segundos")
            print(f"Throughput m√°ximo (V): {data['throughput'].max():.2f} msgs/s")
            print(f"Throughput m√≠nimo (V): {data['throughput'].min():.2f} msgs/s")
            print(f"Lat√™ncia m√≠nima (T): {data['latency_avg'].min():.6f}s")
            print(f"Lat√™ncia m√°xima (T): {data['latency_avg'].max():.6f}s")
            
        except FileNotFoundError:
            print(f"‚ùå Dados n√£o encontrados para {broker}")
        
        print()
    
    # Compara√ß√£o entre brokers
    print("üìà COMPARA√á√ÉO ENTRE BROKERS")
    print("-" * 30)
    
    try:
        baseline_data = pd.read_csv('logs/baseline/benchmark_results.csv')
        rabbitmq_data = pd.read_csv('logs/rabbitmq/benchmark_results.csv')
        kafka_data = pd.read_csv('logs/kafka/benchmark_results.csv')
        
        print(f"Baseline - V (Throughput m√©dio): {baseline_data['throughput'].mean():.2f} mensagens/segundo")
        print(f"Baseline - T (Lat√™ncia m√©dia): {baseline_data['latency_avg'].mean():.6f} segundos")
        print(f"RabbitMQ - V (Throughput m√©dio): {rabbitmq_data['throughput'].mean():.2f} mensagens/segundo")
        print(f"RabbitMQ - T (Lat√™ncia m√©dia): {rabbitmq_data['latency_avg'].mean():.6f} segundos")
        print(f"Kafka    - V (Throughput m√©dio): {kafka_data['throughput'].mean():.2f} mensagens/segundo")
        print(f"Kafka    - T (Lat√™ncia m√©dia): {kafka_data['latency_avg'].mean():.6f} segundos")
        
        print()
        print("üèÜ RANKING DE PERFORMANCE - THROUGHPUT (V):")
        throughputs = {
            'Baseline': baseline_data['throughput'].mean(),
            'RabbitMQ': rabbitmq_data['throughput'].mean(),
            'Kafka': kafka_data['throughput'].mean()
        }
        
        ranking = sorted(throughputs.items(), key=lambda x: x[1], reverse=True)
        for i, (broker, throughput) in enumerate(ranking, 1):
            print(f"{i}¬∫ lugar: {broker} - {throughput:.2f} mensagens/segundo")
        
        print()
        print("üèÜ RANKING DE PERFORMANCE - LAT√äNCIA (T) - Menor √© melhor:")
        latencies = {
            'Baseline': baseline_data['latency_avg'].mean(),
            'RabbitMQ': rabbitmq_data['latency_avg'].mean(),
            'Kafka': kafka_data['latency_avg'].mean()
        }
        
        ranking_lat = sorted(latencies.items(), key=lambda x: x[1])
        for i, (broker, latency) in enumerate(ranking_lat, 1):
            print(f"{i}¬∫ lugar: {broker} - {latency:.6f} segundos")
            
    except FileNotFoundError as e:
        print(f"‚ùå Erro ao carregar dados: {e}")
    
    print()
    print("‚úÖ Relat√≥rio gerado com sucesso!")

if __name__ == "__main__":
    gerar_relatorio()
EOF

# Executar relat√≥rio
python gerar_relatorio.py
```

---

## üîß Solu√ß√£o de Problemas

### Problemas Comuns e Solu√ß√µes

#### 1. **Erro: "Permission denied" no Docker**
```bash
# Verificar se usu√°rio est√° no grupo docker
groups | grep docker

# Se n√£o estiver, adicionar usu√°rio ao grupo
sudo usermod -aG docker $USER

# REINICIAR O TERMINAL e tentar novamente
```

#### 2. **Erro: "Connection refused" nos brokers**
```bash
# Verificar se containers est√£o rodando
docker compose ps

# Se n√£o estiverem, reiniciar
docker compose down
docker compose up -d

# Aguardar inicializa√ß√£o
sleep 60

# Verificar logs
docker compose logs
```

#### 3. **Erro: "No module named 'pika'" ou similar**
```bash
# Verificar se ambiente virtual est√° ativo
which python

# Se n√£o estiver, ativar
source venv/bin/activate

# Reinstalar depend√™ncias
pip install -r requirements.txt
```

#### 4. **Erro: "Port already in use"**
```bash
# Verificar portas em uso
sudo netstat -tlnp | grep -E ":(5672|9092|15672|9000)"

# Parar servi√ßos conflitantes
sudo systemctl stop rabbitmq-server
sudo systemctl stop kafka

# Ou usar portas diferentes no docker-compose.yml
```

#### 5. **Erro: "Container failed to start"**
```bash
# Verificar logs do container
docker compose logs [nome-do-container]

# Verificar recursos do sistema
free -h
df -h

# Limpar containers antigos
docker system prune -a
```

#### 6. **Erro: "RabbitMQ cluster not working"**
```bash
# Verificar status do cluster
docker exec rabbitmq-1 rabbitmqctl cluster_status

# Reinicializar cluster
docker compose restart rabbitmq-1 rabbitmq-2 rabbitmq-3

# Aguardar e verificar novamente
sleep 30
docker exec rabbitmq-1 rabbitmqctl cluster_status
```

#### 7. **Erro: "Kafka topics not created"**
```bash
# Verificar se Kafka est√° funcionando
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# Criar t√≥pico manualmente se necess√°rio
docker exec kafka kafka-topics.sh --create --topic bcc-tcc --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

#### 8. **Erro: "Baseline server not responding"**
```bash
# Verificar se servidor est√° rodando
ps aux | grep "python main.py --server"

# Se n√£o estiver, iniciar manualmente
python main.py --server --port 5000 &

# Testar conectividade
curl -X POST http://localhost:5000/notify -H "Content-Type: application/json" -d '{"message": "test"}'
```

#### 9. **Erro: "Arquivo de tempos de envio n√£o encontrado"**
```bash
# Limpar logs antigos que podem estar causando confus√£o
./scripts/clear_logs.sh

# Executar teste novamente
python main.py --count 5 --size 100 --system rabbitmq
```

#### 10. **Erro: "Mensagem recebida sem timestamp correspondente"**
```bash
# Este erro indica que o consumidor est√° lendo mensagens antigas
# Limpar logs e executar teste limpo
./scripts/clear_logs.sh
python main.py --count 5 --size 100 --system kafka
```

### Logs de Debug

#### Verificar Logs da Aplica√ß√£o
```bash
# Logs gerais
tail -f logs/application.log

# Logs espec√≠ficos de cada broker
tail -f logs/baseline/benchmark_results.csv
tail -f logs/rabbitmq/benchmark_results.csv
tail -f logs/kafka/benchmark_results.csv
```

#### Verificar Logs do Docker
```bash
# Logs de todos os containers
docker compose logs -f

# Logs de um container espec√≠fico
docker compose logs -f rabbitmq-1
docker compose logs -f kafka
```

### Reset Completo do Ambiente

Se nada funcionar, execute um reset completo:

```bash
# Parar tudo
docker compose down -v
deactivate

# Remover ambiente virtual
rm -rf venv

# Limpar Docker
docker system prune -a

# Reconfigurar tudo
./scripts/setup_dev_environment.sh
source venv/bin/activate
docker compose up -d
```

---

## üìö Documenta√ß√£o T√©cnica

### Arquitetura do Sistema

#### Componentes Principais
1. **Orquestrador**: `main.py` - Ponto de entrada √∫nico
2. **Brokers**: Implementa√ß√µes modulares em `src/brokers/`
3. **Core**: Configura√ß√µes e utilit√°rios em `src/core/`
4. **Orquestra√ß√£o**: L√≥gica de testes em `src/orchestration/`

#### Fluxo de Execu√ß√£o
```
main.py ‚Üí BenchmarkOrchestrator ‚Üí Broker Classes ‚Üí Metrics Collection ‚Üí Logs
```

### Configura√ß√µes T√©cnicas

#### RabbitMQ
- **Vers√£o**: 4.1.1 (imagem: `rabbitmq:4.1.1-management`)
- **Cluster**: 3 n√≥s com Quorum Queues
- **Portas**: 5672 (AMQP), 15672 (Management)
- **Configura√ß√µes**: Confirma√ß√£o de entrega, mensagens persistentes

#### Apache Kafka
- **Vers√£o**: 4.0.0 (imagem Docker: `apache/kafka:4.0.0`)
- **Modo**: KRaft (sem Zookeeper)
- **Queue Mode**: Simula√ß√£o de KIP-932
- **Portas**: 9092 (Broker), 9000 (Kafdrop)
- **Nota**: A imagem oficial do Apache Kafka 4.0.0 √© usada com configura√ß√£o KRaft personalizada. O arquivo de configura√ß√£o est√° em `config/kraft-server.properties`.

#### Baseline HTTP
- **Framework**: Flask 3.1.1
- **Porta**: 5000 (configur√°vel via `--port`)
- **Processamento**: 1ms simulado por requisi√ß√£o

### Recursos da Aplica√ß√£o

#### 1. **Benchmark Comparativo Justo**
- Testes comparativos com mesmos par√¢metros para cada porte
- Compara√ß√£o cient√≠fica v√°lida entre Baseline, RabbitMQ e Kafka
- Script automatizado: `test_comparativo_justo_por_porte.sh`

#### 2. **Gera√ß√£o Autom√°tica de Gr√°ficos**
- Gr√°ficos comparativos gerados automaticamente ap√≥s cada benchmark
- Script manual: `python generate_plots.py --system all`
- Tipos de gr√°ficos:
  - Compara√ß√£o de Lat√™ncia
  - Compara√ß√£o de Throughput
  - Resumo Comparativo
  - Distribui√ß√£o de Lat√™ncias

#### 3. **Chaos Engineering**
- Testes de toler√¢ncia a falhas
- Simula√ß√£o de falhas e recupera√ß√£o autom√°tica
- Comando: `python main.py --chaos --count 5 --size 100 --system rabbitmq`
- **Nota**: Para chaos engineering, os par√¢metros `--producers` e `--consumers` s√£o opcionais (padr√£o: 1 produtor, 4 consumidores)

#### 4. **Rate Limiting (RPS)**
- Controle de taxa de mensagens por segundo
- Par√¢metro: `--rps <valor>`
- Valida√ß√£o de throughput controlado

#### 5. **Monitoramento de Recursos**
- Coleta autom√°tica de CPU e mem√≥ria
- Arquivos de monitoramento em `logs/<system>/`

#### 6. **M√©tricas Precisas**
- Lat√™ncia (T) com precis√£o de microssegundos
- Throughput (V) em mensagens por segundo
- Percentis: P50, P95, P99
- Arquivos CSV e JSON para an√°lise posterior

### M√©tricas Coletadas

#### Lat√™ncia
- **T1**: Timestamp ap√≥s confirma√ß√£o do broker
- **T2**: Timestamp ap√≥s processamento
- **Lat√™ncia**: T2 - T1

#### Throughput
- **C√°lculo**: Mensagens processadas / Tempo total
- **Unidade**: Mensagens por segundo

#### Recursos
- **CPU**: Percentual de uso
- **Mem√≥ria**: Uso em MB
- **Coleta**: A cada 5 segundos durante testes

### Valida√ß√£o Cient√≠fica

#### Reprodutibilidade
- **Ambiente**: Docker containerizado
- **Vers√µes**: Fixas e documentadas
- **Configura√ß√µes**: Padronizadas e versionadas

#### M√©tricas
- **Precis√£o**: Timestamps com precis√£o de microssegundos
- **Consist√™ncia**: Mesmo ambiente para todos os testes
- **Comparabilidade**: Mesmas condi√ß√µes para todos os brokers

---

## üéØ Conclus√£o

Este sistema de benchmark foi desenvolvido seguindo rigorosos padr√µes acad√™micos para garantir:

1. **Reprodutibilidade**: Qualquer pesquisador pode replicar os resultados
2. **Precis√£o**: M√©tricas coletadas com alta precis√£o
3. **Completude**: Todos os aspectos relevantes s√£o testados
4. **Documenta√ß√£o**: Processo completamente documentado

### Contato e Suporte

Para d√∫vidas sobre a implementa√ß√£o ou an√°lise dos resultados:
- **E-mail**: leonardosfiamoncini@gmail.com