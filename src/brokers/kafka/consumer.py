"""
Implementa√ß√£o simplificada do consumidor Kafka para TCC
"""

import json
import time
import uuid
from typing import Optional

from kafka import KafkaConsumer, TopicPartition
from kafka.errors import KafkaError

from ...core.config import BROKER_CONFIGS
from ..base import BaseBroker


class KafkaConsumerBroker(BaseBroker):
    """Consumidor Kafka simplificado - mede lat√™ncia real sem depend√™ncias"""

    def __init__(self, run_id: Optional[str] = None):
        super().__init__("kafka", run_id=run_id)
        self.config = BROKER_CONFIGS["kafka"]
        self.run_id = run_id  # Guardar run_id para filtrar mensagens
    
    def send_messages(self, count: int, message_size: int, rps: Optional[int] = None) -> bool:
        """M√©todo n√£o usado por consumidores - apenas para compatibilidade com BaseBroker"""
        return True
    
    def consume_messages(self, expected_count: int, **kwargs) -> bool:
        """
        Consome mensagens do Kafka de forma simples e eficiente
        
        Args:
            expected_count: N√∫mero de mensagens esperadas
        """
        try:
            self.metrics.start_timing()
            
            # Timestamp de in√≠cio para filtrar mensagens antigas
            # Subtrair 2 segundos para capturar mensagens enviadas logo ap√≥s o consumidor iniciar
            start_timestamp = time.time() - 2.0
            
            # Group ID √∫nico para cada execu√ß√£o
            unique_group_id = f"{self.config['group_id']}-{uuid.uuid4().hex[:8]}"
            
            # Configura√ß√£o do consumidor otimizada para baixa lat√™ncia
            consumer = KafkaConsumer(
                self.config["topic"],
                bootstrap_servers=self.config["bootstrap_servers"],
                group_id=unique_group_id,
                auto_offset_reset="earliest",  # Ler desde o in√≠cio para n√£o perder mensagens
                value_deserializer=lambda m: json.loads(m.decode("utf-8")),
                enable_auto_commit=True,
                max_poll_records=100,  # Menos records por poll para processar mais r√°pido
                fetch_min_bytes=1,  # N√£o aguardar acumular dados
                fetch_max_wait_ms=10,  # Tempo m√≠nimo de espera para reduzir lat√™ncia
                session_timeout_ms=30000,
                request_timeout_ms=31000,
            )
            
            self.logger.info(f"‚úÖ Consumidor Kafka conectado ao t√≥pico {self.config['topic']}")
            
            # Subscribe to the topic
            consumer.subscribe([self.config["topic"]])
            
            # Fazer um poll inicial para garantir que estamos conectados
            consumer.poll(timeout_ms=100)
            
            received_count = 0
            latencies = []
            valid_messages = 0
            start_time = time.time()
            timeout = max(60, expected_count / 50)  # Timeout din√¢mico
            empty_polls = 0
            max_empty_polls = 20  # Aumentar para dar mais tempo
            
            self.logger.info(f"Aguardando {expected_count} mensagens (run_id: {self.run_id})...")
            
            # Consumir mensagens
            while received_count < expected_count:
                # Verificar timeout
                if time.time() - start_time > timeout:
                    self.logger.warning(f"Timeout ap√≥s {timeout}s. Recebidas {received_count}/{expected_count}")
                    break
                
                # Poll por mensagens
                messages = consumer.poll(timeout_ms=500)  # Poll mais frequente
                
                if not messages:
                    empty_polls += 1
                    if empty_polls > max_empty_polls and received_count == 0:
                        self.logger.warning(f"Nenhuma mensagem recebida ap√≥s {max_empty_polls} tentativas")
                        break
                    # Aguardar um pouco mais se ainda n√£o recebemos mensagens
                    if received_count == 0:
                        time.sleep(0.1)
                    continue
                else:
                    empty_polls = 0  # Reset counter se recebemos mensagens
                
                # Processar mensagens recebidas
                for topic_partition, records in messages.items():
                    for message in records:
                        try:
                            # Calcular lat√™ncia
                            current_time = time.time()
                            msg_data = message.value
                            
                            # Processar apenas mensagens com estrutura v√°lida
                            if isinstance(msg_data, dict):
                                # Verificar run_id se presente
                                msg_run_id = msg_data.get("run_id", "")
                                
                                # Se a mensagem tem run_id e n√£o corresponde, pular
                                if msg_run_id and self.run_id and msg_run_id != self.run_id:
                                    continue
                                
                                # Verificar timestamp
                                if "timestamp" in msg_data:
                                    send_time = msg_data["timestamp"]
                                    
                                    # FILTRO CR√çTICO: Apenas mensagens enviadas AP√ìS o in√≠cio desta execu√ß√£o
                                    if send_time < start_timestamp - 1:  # -1 segundo de toler√¢ncia
                                        continue  # Mensagem de execu√ß√£o anterior
                                    
                                    latency = current_time - send_time
                                    
                                    # Validar lat√™ncia (m√°ximo 30 segundos)
                                    if 0 <= latency <= 30:
                                        latencies.append(latency)
                                        self.metrics.record_latency(latency, str(received_count + 1))
                                        valid_messages += 1
                                    else:
                                        self.logger.debug(f"Lat√™ncia inv√°lida ignorada: {latency:.3f}s")
                            
                            received_count += 1
                            
                            # Log de progresso
                            if received_count <= 10 or received_count % 100 == 0:
                                self.logger.info(f"Recebidas {received_count}/{expected_count} mensagens (v√°lidas: {valid_messages})")
                            
                            if received_count >= expected_count:
                                break
                                
                        except Exception as e:
                            self.logger.warning(f"Erro ao processar mensagem: {e}")
                            continue
                    
                    if received_count >= expected_count:
                        break
            
            # Fechar consumidor
            consumer.close()
            
            # Finalizar m√©tricas
            self.metrics.end_timing()
            self.metrics.messages_consumed = valid_messages  # Usar apenas mensagens v√°lidas
            self.metrics.save_latencies()
            self.metrics.save_summary()
            
            # Log resumo
            if latencies:
                avg_latency = sum(latencies) / len(latencies)
                self.logger.info(f"üìä Lat√™ncia m√©dia: {avg_latency:.3f}s")
                
                # Alertar se lat√™ncia m√©dia est√° muito alta
                if avg_latency > 1.0:
                    self.logger.warning(f"‚ö†Ô∏è Lat√™ncia m√©dia muito alta: {avg_latency:.3f}s - poss√≠vel consumo de mensagens antigas!")
            
            self.logger.info(f"‚úÖ Consumo finalizado: {valid_messages} mensagens v√°lidas recebidas de {received_count} total")
            
            return valid_messages >= expected_count
            
        except Exception as e:
            self.logger.error(f"‚ùå Erro no consumidor Kafka: {e}")
            return False