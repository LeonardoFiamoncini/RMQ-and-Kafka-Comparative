# üéì Benchmark Comparativo para TCC

**Trabalho de Conclus√£o de Curso (TCC) - Bacharelado em Ci√™ncia da Computa√ß√£o**

Este projeto implementa um sistema completo de benchmark comparativo entre **RabbitMQ**, **Apache Kafka** e **HTTP S√≠ncrono**, desenvolvido para an√°lise de performance, toler√¢ncia a falhas e escalabilidade de sistemas de mensageria. O sistema foi projetado seguindo rigorosos padr√µes acad√™micos e de engenharia de software.

## üìã √çndice

1. [Vis√£o Geral do Projeto](#-vis√£o-geral-do-projeto)
2. [Pr√©-requisitos do Sistema](#-pr√©-requisitos-do-sistema)
3. [Instala√ß√£o Completa](#-instala√ß√£o-completa)
4. [Configura√ß√£o do Ambiente](#-configura√ß√£o-do-ambiente)
5. [Execu√ß√£o de Todos os Testes](#-execu√ß√£o-de-todos-os-testes)
6. [An√°lise e Visualiza√ß√£o dos Resultados](#-an√°lise-e-visualiza√ß√£o-dos-resultados)
7. [Interpreta√ß√£o dos Resultados](#-interpreta√ß√£o-dos-resultados)
8. [Solu√ß√£o de Problemas](#-solu√ß√£o-de-problemas)
9. [Documenta√ß√£o T√©cnica](#-documenta√ß√£o-t√©cnica)

---

## üéØ Vis√£o Geral do Projeto

### Objetivos Acad√™micos
- **Compara√ß√£o Quantitativa**: An√°lise estat√≠stica de performance entre RabbitMQ, Kafka e HTTP
- **Toler√¢ncia a Falhas**: Avalia√ß√£o de recupera√ß√£o e disponibilidade em cen√°rios de falha
- **Escalabilidade**: Teste de comportamento com m√∫ltiplos clientes concorrentes
- **Reprodutibilidade**: Metodologia cient√≠fica rigorosa para replica√ß√£o dos resultados

### Tecnologias Implementadas
- **RabbitMQ 4.1.1** (imagem: `rabbitmq:4.1.1-management`): Com Quorum Queues e cluster de 3 n√≥s
- **Apache Kafka 4.0** (imagem: `bitnami/kafka:3.6`): Com KRaft mode e Queue Mode (KIP-932)
- **HTTP S√≠ncrono**: Baseline para compara√ß√£o de lat√™ncia (Flask)
- **Docker**: Containeriza√ß√£o completa da infraestrutura
- **Python 3.12+**: Implementa√ß√£o dos clientes e orquestra√ß√£o
- **Kafdrop 3.30.0**: Interface web para monitoramento do Kafka

### M√©tricas Coletadas
- **Lat√™ncia End-to-End**: Tempo total de envio at√© processamento
- **Throughput**: Mensagens processadas por segundo
- **Taxa de Sucesso**: Percentual de entrega garantida
- **Uso de Recursos**: CPU e mem√≥ria dos brokers
- **Tempo de Recupera√ß√£o**: Ap√≥s falhas simuladas

---

## üñ•Ô∏è Pr√©-requisitos do Sistema

### Especifica√ß√µes M√≠nimas
- **Sistema Operacional**: 
  - **Linux**: Ubuntu 22.04 LTS ou superior, Debian 11+, Fedora 36+, ou qualquer distribui√ß√£o com suporte a Docker
  - **macOS**: macOS 11 (Big Sur) ou superior
  - **Windows**: Windows 10/11 com WSL2 ou Docker Desktop
- **RAM**: M√≠nimo 4GB (recomendado 8GB)
- **CPU**: M√≠nimo 2 cores (recomendado 4 cores)
- **Armazenamento**: M√≠nimo 10GB livres
- **Rede**: Conex√£o com internet para download de depend√™ncias

### Software Necess√°rio
- **Docker**: Vers√£o 20.10 ou superior
- **Docker Compose**: Vers√£o 2.0 ou superior (plugin ou standalone)
- **Python**: Vers√£o 3.10 ou superior (3.12 recomendado)
- **Git**: Para clonagem do reposit√≥rio
- **Curl**: Para testes de conectividade
- **Bash**: Para execu√ß√£o dos scripts de setup (Linux/macOS) ou Git Bash/WSL (Windows)

### Verifica√ß√£o dos Pr√©-requisitos

#### Linux (Ubuntu/Debian/Fedora)
```bash
# Verificar vers√£o do sistema
lsb_release -a 2>/dev/null || cat /etc/os-release

# Verificar RAM dispon√≠vel
free -h

# Verificar CPU
lscpu | grep "CPU(s):"

# Verificar espa√ßo em disco
df -h

# Verificar Docker
docker --version
docker compose version

# Verificar Python
python3 --version
pip3 --version
```

#### macOS
```bash
# Verificar vers√£o do macOS
sw_vers

# Verificar RAM dispon√≠vel
sysctl hw.memsize | awk '{print $2/1024/1024/1024 " GB"}'

# Verificar CPU
sysctl -n hw.ncpu

# Verificar espa√ßo em disco
df -h

# Verificar Docker
docker --version
docker compose version

# Verificar Python
python3 --version
pip3 --version
```

#### Windows (WSL2 ou Docker Desktop)
```powershell
# No PowerShell ou WSL
# Verificar vers√£o do Windows
systeminfo | findstr /B /C:"OS Name" /C:"OS Version"

# Verificar Docker
docker --version
docker compose version

# Verificar Python (no WSL)
python3 --version
pip3 --version
```

---

## üöÄ Instala√ß√£o Completa

### Passo 1: Clonagem do Reposit√≥rio
```bash
# Clonar o reposit√≥rio
git clone <URL_DO_REPOSITORIO>
cd RMQ-and-Kafka-Comparative

# Verificar estrutura do projeto
ls -la
```

### Passo 2: Configura√ß√£o Autom√°tica do Ambiente

**Compatibilidade Multi-OS**: O script `setup_dev_environment.sh` funciona em Linux e macOS. Para Windows, use WSL2 ou Docker Desktop.

#### Linux/macOS
```bash
# Dar permiss√µes de execu√ß√£o
chmod +x scripts/setup_dev_environment.sh

# Executar configura√ß√£o autom√°tica
./scripts/setup_dev_environment.sh
```

#### Windows (WSL2)
```bash
# No terminal WSL2
chmod +x scripts/setup_dev_environment.sh
./scripts/setup_dev_environment.sh
```

#### Windows (Docker Desktop)
```powershell
# Instalar Docker Desktop manualmente:
# https://www.docker.com/products/docker-desktop

# No PowerShell ou WSL2, instalar Python e depend√™ncias:
python -m venv venv
.\venv\Scripts\activate  # PowerShell
# ou
source venv/bin/activate  # WSL2

pip install -r requirements.txt
```

**‚ö†Ô∏è IMPORTANTE**: Durante a execu√ß√£o do script:
- Digite sua senha quando solicitado (Linux/macOS)
- Aguarde a instala√ß√£o do Docker (pode demorar alguns minutos)
- **REINICIE O TERMINAL** ap√≥s a conclus√£o para aplicar permiss√µes do Docker (Linux)

### Passo 3: Verifica√ß√£o da Instala√ß√£o
```bash
# Verificar se o usu√°rio est√° no grupo docker
groups | grep docker

# Se n√£o aparecer "docker", reinicie o terminal e tente novamente

# Ativar ambiente virtual
source venv/bin/activate

# Verificar instala√ß√£o das depend√™ncias
pip list | grep -E -i "(flask|pika|kafka-python|requests|black|isort|flake8)"
```

### Passo 4: Inicializa√ß√£o da Infraestrutura
```bash
# Iniciar todos os servi√ßos
docker compose up -d

# Aguardar inicializa√ß√£o (30-60 segundos)
sleep 60

# Verificar status dos containers
docker compose ps
```

**Resultado esperado**: Todos os containers devem estar com status "Up"

---

## ‚öôÔ∏è Configura√ß√£o do Ambiente

### Verifica√ß√£o dos Servi√ßos

#### 1. RabbitMQ Cluster (3 n√≥s)
```bash
# Verificar cluster RabbitMQ
docker exec rabbitmq-1 rabbitmqctl cluster_status

# Verificar filas
docker exec rabbitmq-1 rabbitmqctl list_queues

# Acessar interface web
echo "RabbitMQ Management: http://localhost:15672"
echo "Usu√°rio: user | Senha: password"
```

#### 2. Apache Kafka
```bash
# Verificar t√≥picos Kafka
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# Verificar brokers
docker exec kafka kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# Acessar interface web
echo "Kafdrop: http://localhost:9000"
```

#### 3. Teste de Conectividade
```bash
# Testar RabbitMQ
curl -u user:password http://localhost:15672/api/overview

# Testar Kafka (via Kafdrop)
curl -s http://localhost:9000 | grep -i kafdrop

# Testar baseline HTTP (ser√° iniciado nos testes)
```

---

## üß™ Execu√ß√£o de Todos os Testes

### ‚ö†Ô∏è Prepara√ß√£o Importante

**ANTES de executar qualquer teste, execute estes comandos:**

```bash
# 1. Ativar ambiente virtual
source venv/bin/activate

# 2. Verificar se containers est√£o rodando
docker compose ps

# 3. Se n√£o estiverem, iniciar
docker compose up -d
sleep 60

# 4. Limpar logs antigos (IMPORTANTE!)
./scripts/clear_logs.sh

# 5. Verificar conectividade
echo "Testando RabbitMQ..."
curl -u user:password http://localhost:15672/api/overview | head -1

echo "Testando Kafka..."
curl -s http://localhost:9000 | grep -i kafdrop | head -1
```

### Estrutura dos Testes

O sistema executa **8 categorias principais de testes**, cada uma validando aspectos espec√≠ficos da aplica√ß√£o:

1. **Testes B√°sicos de Funcionalidade**
2. **Testes de Rate Limiting (RPS)**
3. **Testes de M√∫ltiplos Clientes**
4. **Testes de Chaos Engineering**
5. **Testes de Monitoramento**
6. **Testes Integrados**
7. **Testes de Baseline HTTP**
8. **Testes de Performance Comparativa**

### Execu√ß√£o Sequencial de Todos os Testes

#### **TESTE 1: Valida√ß√£o B√°sica dos Brokers**

```bash
# Ativar ambiente virtual
source venv/bin/activate

# Teste 1.1: Baseline HTTP (com servidor)
echo "=== TESTE 1.1: Baseline HTTP ==="
# Iniciar servidor em background
python main.py --server --port 5000 &
sleep 3
# Executar teste
python main.py --count 10 --size 200 --only baseline
# Parar servidor
pkill -f "python main.py --server"

# Teste 1.2: RabbitMQ
echo "=== TESTE 1.2: RabbitMQ ==="
python main.py --count 8 --size 150 --only rabbitmq

# Teste 1.3: Kafka
echo "=== TESTE 1.3: Kafka ==="
python main.py --count 8 --size 150 --only kafka
```

**‚úÖ Crit√©rio de Sucesso**: Todos os testes devem mostrar "‚úÖ Benchmark finalizado" sem erros.

#### **TESTE 2: Rate Limiting (RPS)**

```bash
# Teste 2.1: Baseline com RPS
echo "=== TESTE 2.1: Baseline com Rate Limiting ==="
python main.py --count 8 --size 100 --rps 3 --only baseline

# Teste 2.2: RabbitMQ com RPS
echo "=== TESTE 2.2: RabbitMQ com Rate Limiting ==="
python main.py --count 6 --size 100 --rps 2 --only rabbitmq

# Teste 2.3: Kafka com RPS
echo "=== TESTE 2.3: Kafka com Rate Limiting ==="
python main.py --count 6 --size 100 --rps 2 --only kafka
```

**‚úÖ Crit√©rio de Sucesso**: Throughput deve estar pr√≥ximo ao RPS especificado.

#### **TESTE 3: M√∫ltiplos Clientes Concorrentes**

```bash
# Teste 3.1: Baseline com m√∫ltiplos clientes
echo "=== TESTE 3.1: Baseline - M√∫ltiplos Clientes ==="
python main.py --count 12 --size 100 --producers 3 --consumers 2 --only baseline

# Teste 3.2: RabbitMQ com m√∫ltiplos clientes
echo "=== TESTE 3.2: RabbitMQ - M√∫ltiplos Clientes ==="
python main.py --count 8 --size 100 --producers 2 --consumers 2 --only rabbitmq

# Teste 3.3: Kafka com m√∫ltiplos clientes
echo "=== TESTE 3.3: Kafka - M√∫ltiplos Clientes ==="
python main.py --count 8 --size 100 --producers 2 --consumers 2 --only kafka
```

**‚úÖ Crit√©rio de Sucesso**: Throughput deve aumentar proporcionalmente ao n√∫mero de clientes.

#### **TESTE 4: Chaos Engineering (Toler√¢ncia a Falhas)**

```bash
# Teste 4.1: Chaos Engineering - RabbitMQ
echo "=== TESTE 4.1: Chaos Engineering - RabbitMQ ==="
python main.py --chaos --count 5 --size 100 --only rabbitmq

# Aguardar recupera√ß√£o
sleep 30

# Teste 4.2: Chaos Engineering - Kafka
echo "=== TESTE 4.2: Chaos Engineering - Kafka ==="
python main.py --chaos --count 5 --size 100 --only kafka

# Aguardar recupera√ß√£o
sleep 30
```

**‚úÖ Crit√©rio de Sucesso**: Sistema deve se recuperar automaticamente ap√≥s falhas.

#### **TESTE 5: Monitoramento de Recursos**

```bash
# Teste 5.1: Monitoramento - RabbitMQ
echo "=== TESTE 5.1: Monitoramento - RabbitMQ ==="
python main.py --count 5 --size 100 --only rabbitmq

# Teste 5.2: Monitoramento - Kafka
echo "=== TESTE 5.2: Monitoramento - Kafka ==="
python main.py --count 5 --size 100 --only kafka
```

**‚úÖ Crit√©rio de Sucesso**: Arquivos de monitoramento devem ser gerados em `logs/`.

#### **TESTE 6: Benchmarks Integrados**

```bash
# Teste 6.1: Benchmark Completo (Todos os Brokers)
echo "=== TESTE 6.1: Benchmark Completo ==="
python main.py --count 10 --size 100

# Teste 6.2: Benchmark com Rate Limiting
echo "=== TESTE 6.2: Benchmark com Rate Limiting ==="
python main.py --count 20 --size 100 --rps 5

# Teste 6.3: Benchmark com M√∫ltiplos Clientes
echo "=== TESTE 6.3: Benchmark com M√∫ltiplos Clientes ==="
python main.py --count 30 --size 100 --producers 3 --consumers 2
```

**‚úÖ Crit√©rio de Sucesso**: Todos os brokers devem ser testados em sequ√™ncia.

#### **TESTE 7: Baseline HTTP Detalhado**

```bash
# Teste 7.1: Iniciar servidor baseline
echo "=== TESTE 7.1: Iniciando Servidor Baseline ==="
python main.py --server --port 5000 &

# Aguardar inicializa√ß√£o
sleep 5

# Teste 7.2: Testar cliente baseline
echo "=== TESTE 7.2: Testando Cliente Baseline ==="
python main.py --count 15 --size 100 --only baseline

# Parar servidor
pkill -f "python main.py --server"
```

**‚úÖ Crit√©rio de Sucesso**: Servidor deve responder e processar requisi√ß√µes.

#### **TESTE 8: Performance Comparativa Extensiva**

```bash
# Teste 8.1: Performance com diferentes tamanhos de mensagem
echo "=== TESTE 8.1: Performance - Tamanhos Variados ==="
python main.py --count 50 --size 64 --only baseline
python main.py --count 50 --size 64 --only rabbitmq
python main.py --count 50 --size 64 --only kafka

python main.py --count 50 --size 1024 --only baseline
python main.py --count 50 --size 1024 --only rabbitmq
python main.py --count 50 --size 1024 --only kafka

python main.py --count 50 --size 4096 --only baseline
python main.py --count 50 --size 4096 --only rabbitmq
python main.py --count 50 --size 4096 --only kafka

# Teste 8.2: Performance com diferentes cargas
echo "=== TESTE 8.2: Performance - Cargas Variadas ==="
python main.py --count 100 --size 100 --only baseline
python main.py --count 100 --size 100 --only rabbitmq
python main.py --count 100 --size 100 --only kafka

python main.py --count 500 --size 100 --only baseline
python main.py --count 500 --size 100 --only rabbitmq
python main.py --count 500 --size 100 --only kafka
```

**‚úÖ Crit√©rio de Sucesso**: Dados suficientes para an√°lise estat√≠stica.

### Script de Execu√ß√£o Autom√°tica

Para executar todos os testes automaticamente:

```bash
# Criar script de execu√ß√£o completa
cat > executar_todos_testes.sh << 'EOF'
#!/bin/bash

echo "üéì INICIANDO EXECU√á√ÉO COMPLETA DE TODOS OS TESTES"
echo "=================================================="

# Ativar ambiente virtual
source venv/bin/activate

# Limpar logs antigos para evitar confus√£o
echo "üßπ Limpando logs antigos..."
./scripts/clear_logs.sh

# Verificar se containers est√£o rodando
if ! docker compose ps | grep -q "Up"; then
    echo "‚ùå Containers n√£o est√£o rodando. Iniciando..."
    docker compose up -d
    sleep 60
fi

# Executar todos os testes
echo "üß™ Executando Teste 1: Valida√ß√£o B√°sica"
# Baseline com servidor
python main.py --server --port 5000 &
sleep 3
python main.py --count 10 --size 200 --only baseline
pkill -f "python main.py --server"
# RabbitMQ e Kafka
python main.py --count 8 --size 150 --only rabbitmq
python main.py --count 8 --size 150 --only kafka

echo "üß™ Executando Teste 2: Rate Limiting"
python main.py --count 8 --size 100 --rps 3 --only baseline
python main.py --count 6 --size 100 --rps 2 --only rabbitmq
python main.py --count 6 --size 100 --rps 2 --only kafka

echo "üß™ Executando Teste 3: M√∫ltiplos Clientes"
python main.py --count 12 --size 100 --producers 3 --consumers 2 --only baseline
python main.py --count 8 --size 100 --producers 2 --consumers 2 --only rabbitmq
python main.py --count 8 --size 100 --producers 2 --consumers 2 --only kafka

echo "üß™ Executando Teste 4: Chaos Engineering"
python main.py --chaos --count 5 --size 100 --only rabbitmq
sleep 30
python main.py --chaos --count 5 --size 100 --only kafka
sleep 30

echo "üß™ Executando Teste 5: Monitoramento"
python main.py --count 5 --size 100 --only rabbitmq
python main.py --count 5 --size 100 --only kafka

echo "üß™ Executando Teste 6: Benchmarks Integrados"
python main.py --count 10 --size 100
python main.py --count 20 --size 100 --rps 5
python main.py --count 30 --size 100 --producers 3 --consumers 2

echo "üß™ Executando Teste 7: Baseline HTTP"
python main.py --server --port 5000 &
sleep 5
python main.py --count 15 --size 100 --only baseline
pkill -f "python main.py --server"

echo "üß™ Executando Teste 8: Performance Comparativa"
python main.py --count 100 --size 100 --only baseline
python main.py --count 100 --size 100 --only rabbitmq
python main.py --count 100 --size 100 --only kafka

echo "‚úÖ TODOS OS TESTES CONCLU√çDOS COM SUCESSO!"
echo "üìä Verifique os resultados em: logs/"
EOF

# Dar permiss√£o de execu√ß√£o
chmod +x executar_todos_testes.sh

# Executar todos os testes
./executar_todos_testes.sh
```

---

## üìä An√°lise e Visualiza√ß√£o dos Resultados

### Estrutura dos Logs Gerados

```
logs/
‚îú‚îÄ‚îÄ baseline/
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
‚îÇ   ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
‚îÇ   ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
‚îÇ   ‚îî‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
‚îÇ   ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
‚îÇ   ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
‚îÇ   ‚îú‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
‚îÇ   ‚îî‚îÄ‚îÄ resource_monitoring.csv        # Monitoramento de recursos
‚îî‚îÄ‚îÄ rabbitmq/
    ‚îú‚îÄ‚îÄ benchmark_results.csv          # Resultados consolidados
    ‚îú‚îÄ‚îÄ [timestamp]_send_times.json    # Timestamps de envio
    ‚îú‚îÄ‚îÄ [timestamp]_latency.csv        # Medi√ß√µes de lat√™ncia
    ‚îú‚îÄ‚îÄ [timestamp]_summary.csv        # Resumo estat√≠stico
    ‚îî‚îÄ‚îÄ resource_monitoring.csv        # Monitoramento de recursos
```

### An√°lise dos Resultados

#### 1. Visualiza√ß√£o dos Resultados Consolidados
```bash
# Ver resultados consolidados de cada broker
echo "=== RESULTADOS BASELINE ==="
cat logs/baseline/benchmark_results.csv

echo "=== RESULTADOS RABBITMQ ==="
cat logs/rabbitmq/benchmark_results.csv

echo "=== RESULTADOS KAFKA ==="
cat logs/kafka/benchmark_results.csv
```

#### 2. An√°lise de Lat√™ncia
```bash
# Analisar lat√™ncias mais recentes
echo "=== LAT√äNCIAS BASELINE ==="
ls -la logs/baseline/*latency.csv | tail -1 | xargs cat

echo "=== LAT√äNCIAS RABBITMQ ==="
ls -la logs/rabbitmq/*latency.csv | tail -1 | xargs cat

echo "=== LAT√äNCIAS KAFKA ==="
ls -la logs/kafka/*latency.csv | tail -1 | xargs cat
```

#### 3. An√°lise de Throughput
```bash
# Extrair throughput dos summaries
echo "=== THROUGHPUT BASELINE ==="
ls -la logs/baseline/*summary.csv | tail -1 | xargs grep "throughput"

echo "=== THROUGHPUT RABBITMQ ==="
ls -la logs/rabbitmq/*summary.csv | tail -1 | xargs grep "throughput"

echo "=== THROUGHPUT KAFKA ==="
ls -la logs/kafka/*summary.csv | tail -1 | xargs grep "throughput"
```

#### 4. Monitoramento de Recursos
```bash
# Verificar monitoramento de recursos
echo "=== RECURSOS RABBITMQ ==="
ls -la logs/rabbitmq/*resource_monitoring.csv | tail -1 | xargs head -10

echo "=== RECURSOS KAFKA ==="
ls -la logs/kafka/*resource_monitoring.csv | tail -1 | xargs head -10
```

### Visualiza√ß√£o Gr√°fica (Opcional)

#### Instala√ß√£o de Ferramentas de Visualiza√ß√£o
```bash
# Instalar ferramentas para an√°lise de dados
pip install pandas matplotlib seaborn numpy

# Criar script de visualiza√ß√£o
cat > visualizar_resultados.py << 'EOF'
#!/usr/bin/env python3
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os

def plot_benchmark_results():
    """Criar gr√°ficos dos resultados de benchmark"""
    
    # Carregar dados
    baseline_data = pd.read_csv('logs/baseline/benchmark_results.csv')
    rabbitmq_data = pd.read_csv('logs/rabbitmq/benchmark_results.csv')
    kafka_data = pd.read_csv('logs/kafka/benchmark_results.csv')
    
    # Combinar dados
    all_data = pd.concat([
        baseline_data.assign(broker='Baseline'),
        rabbitmq_data.assign(broker='RabbitMQ'),
        kafka_data.assign(broker='Kafka')
    ])
    
    # Criar gr√°ficos
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Throughput por broker
    sns.barplot(data=all_data, x='broker', y='throughput', ax=axes[0,0])
    axes[0,0].set_title('Throughput por Broker')
    axes[0,0].set_ylabel('Mensagens/segundo')
    
    # Lat√™ncia por broker
    sns.barplot(data=all_data, x='broker', y='avg_latency', ax=axes[0,1])
    axes[0,1].set_title('Lat√™ncia M√©dia por Broker')
    axes[0,1].set_ylabel('Lat√™ncia (segundos)')
    
    # Taxa de sucesso
    sns.barplot(data=all_data, x='broker', y='success_rate', ax=axes[1,0])
    axes[1,0].set_title('Taxa de Sucesso por Broker')
    axes[1,0].set_ylabel('Taxa de Sucesso (%)')
    
    # Dura√ß√£o total
    sns.barplot(data=all_data, x='broker', y='duration', ax=axes[1,1])
    axes[1,1].set_title('Dura√ß√£o Total por Broker')
    axes[1,1].set_ylabel('Dura√ß√£o (segundos)')
    
    plt.tight_layout()
    plt.savefig('benchmark_results.png', dpi=300, bbox_inches='tight')
    print("üìä Gr√°fico salvo como: benchmark_results.png")

if __name__ == "__main__":
    plot_benchmark_results()
EOF

# Executar visualiza√ß√£o
python visualizar_resultados.py
```

---

## üìà Interpreta√ß√£o dos Resultados

### M√©tricas Principais

#### 1. **Throughput (Mensagens/segundo)**
- **Baseline HTTP**: Esperado 50-200 msgs/s
- **RabbitMQ**: Esperado 1,000-5,000 msgs/s
- **Apache Kafka**: Esperado 5,000-20,000 msgs/s

#### 2. **Lat√™ncia (Segundos)**
- **Baseline HTTP**: Esperado 0.001-0.010s
- **RabbitMQ**: Esperado 0.001-0.005s
- **Apache Kafka**: Esperado 0.001-0.003s

#### 3. **Taxa de Sucesso (%)**
- **Todos os brokers**: Esperado 95-100%

#### 4. **Uso de Recursos**
- **CPU**: Varia conforme carga
- **Mem√≥ria**: RabbitMQ ~200MB, Kafka ~300MB

### An√°lise Comparativa

#### Cen√°rio 1: Mensagens Pequenas (100 bytes)
```bash
# Executar teste espec√≠fico
python main.py --count 100 --size 100 --only baseline
python main.py --count 100 --size 100 --only rabbitmq
python main.py --count 100 --size 100 --only kafka

# Analisar resultados
echo "=== COMPARA√á√ÉO - MENSAGENS PEQUENAS ==="
echo "Baseline: $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f3) msgs/s"
echo "RabbitMQ: $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f3) msgs/s"
echo "Kafka:    $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f3) msgs/s"
```

#### Cen√°rio 2: Mensagens Grandes (4KB)
```bash
# Executar teste espec√≠fico
python main.py --count 50 --size 4096 --only baseline
python main.py --count 50 --size 4096 --only rabbitmq
python main.py --count 50 --size 4096 --only kafka

# Analisar resultados
echo "=== COMPARA√á√ÉO - MENSAGENS GRANDES ==="
echo "Baseline: $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f3) msgs/s"
echo "RabbitMQ: $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f3) msgs/s"
echo "Kafka:    $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f3) msgs/s"
```

#### Cen√°rio 3: Rate Limiting
```bash
# Executar teste com rate limiting
python main.py --count 20 --size 100 --rps 5 --only baseline
python main.py --count 20 --size 100 --rps 5 --only rabbitmq
python main.py --count 20 --size 100 --rps 5 --only kafka

# Verificar se rate limiting funcionou
echo "=== VERIFICA√á√ÉO RATE LIMITING ==="
echo "Baseline: $(tail -1 logs/baseline/benchmark_results.csv | cut -d',' -f3) msgs/s (esperado ~5)"
echo "RabbitMQ: $(tail -1 logs/rabbitmq/benchmark_results.csv | cut -d',' -f3) msgs/s (esperado ~5)"
echo "Kafka:    $(tail -1 logs/kafka/benchmark_results.csv | cut -d',' -f3) msgs/s (esperado ~5)"
```

### Relat√≥rio de An√°lise

#### Gerar Relat√≥rio Autom√°tico
```bash
# Criar script de relat√≥rio
cat > gerar_relatorio.py << 'EOF'
#!/usr/bin/env python3
import pandas as pd
import glob
import os
from datetime import datetime

def gerar_relatorio():
    """Gerar relat√≥rio completo dos resultados"""
    
    print("üìä RELAT√ìRIO DE AN√ÅLISE DE PERFORMANCE")
    print("=" * 50)
    print(f"Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Analisar cada broker
    brokers = ['baseline', 'rabbitmq', 'kafka']
    
    for broker in brokers:
        print(f"üîç AN√ÅLISE DO {broker.upper()}")
        print("-" * 30)
        
        # Carregar dados
        try:
            data = pd.read_csv(f'logs/{broker}/benchmark_results.csv')
            
            # Estat√≠sticas b√°sicas
            print(f"Total de testes: {len(data)}")
            print(f"Throughput m√©dio: {data['throughput'].mean():.2f} msgs/s")
            print(f"Lat√™ncia m√©dia: {data['avg_latency'].mean():.6f}s")
            print(f"Taxa de sucesso m√©dia: {data['success_rate'].mean():.2f}%")
            print(f"Throughput m√°ximo: {data['throughput'].max():.2f} msgs/s")
            print(f"Throughput m√≠nimo: {data['throughput'].min():.2f} msgs/s")
            
        except FileNotFoundError:
            print(f"‚ùå Dados n√£o encontrados para {broker}")
        
        print()
    
    # Compara√ß√£o entre brokers
    print("üìà COMPARA√á√ÉO ENTRE BROKERS")
    print("-" * 30)
    
    try:
        baseline_data = pd.read_csv('logs/baseline/benchmark_results.csv')
        rabbitmq_data = pd.read_csv('logs/rabbitmq/benchmark_results.csv')
        kafka_data = pd.read_csv('logs/kafka/benchmark_results.csv')
        
        print(f"Baseline - Throughput m√©dio: {baseline_data['throughput'].mean():.2f} msgs/s")
        print(f"RabbitMQ - Throughput m√©dio: {rabbitmq_data['throughput'].mean():.2f} msgs/s")
        print(f"Kafka    - Throughput m√©dio: {kafka_data['throughput'].mean():.2f} msgs/s")
        
        print()
        print("üèÜ RANKING DE PERFORMANCE:")
        throughputs = {
            'Baseline': baseline_data['throughput'].mean(),
            'RabbitMQ': rabbitmq_data['throughput'].mean(),
            'Kafka': kafka_data['throughput'].mean()
        }
        
        ranking = sorted(throughputs.items(), key=lambda x: x[1], reverse=True)
        for i, (broker, throughput) in enumerate(ranking, 1):
            print(f"{i}¬∫ lugar: {broker} - {throughput:.2f} msgs/s")
            
    except FileNotFoundError as e:
        print(f"‚ùå Erro ao carregar dados: {e}")
    
    print()
    print("‚úÖ Relat√≥rio gerado com sucesso!")

if __name__ == "__main__":
    gerar_relatorio()
EOF

# Executar relat√≥rio
python gerar_relatorio.py
```

---

## üîß Solu√ß√£o de Problemas

### Problemas Comuns e Solu√ß√µes

#### 1. **Erro: "Permission denied" no Docker**
```bash
# Verificar se usu√°rio est√° no grupo docker
groups | grep docker

# Se n√£o estiver, adicionar usu√°rio ao grupo
sudo usermod -aG docker $USER

# REINICIAR O TERMINAL e tentar novamente
```

#### 2. **Erro: "Connection refused" nos brokers**
```bash
# Verificar se containers est√£o rodando
docker compose ps

# Se n√£o estiverem, reiniciar
docker compose down
docker compose up -d

# Aguardar inicializa√ß√£o
sleep 60

# Verificar logs
docker compose logs
```

#### 3. **Erro: "No module named 'pika'" ou similar**
```bash
# Verificar se ambiente virtual est√° ativo
which python

# Se n√£o estiver, ativar
source venv/bin/activate

# Reinstalar depend√™ncias
pip install -r requirements.txt
```

#### 4. **Erro: "Port already in use"**
```bash
# Verificar portas em uso
sudo netstat -tlnp | grep -E ":(5672|9092|15672|9000)"

# Parar servi√ßos conflitantes
sudo systemctl stop rabbitmq-server
sudo systemctl stop kafka

# Ou usar portas diferentes no docker-compose.yml
```

#### 5. **Erro: "Container failed to start"**
```bash
# Verificar logs do container
docker compose logs [nome-do-container]

# Verificar recursos do sistema
free -h
df -h

# Limpar containers antigos
docker system prune -a
```

#### 6. **Erro: "RabbitMQ cluster not working"**
```bash
# Verificar status do cluster
docker exec rabbitmq-1 rabbitmqctl cluster_status

# Reinicializar cluster
docker compose restart rabbitmq-1 rabbitmq-2 rabbitmq-3

# Aguardar e verificar novamente
sleep 30
docker exec rabbitmq-1 rabbitmqctl cluster_status
```

#### 7. **Erro: "Kafka topics not created"**
```bash
# Verificar se Kafka est√° funcionando
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# Criar t√≥pico manualmente se necess√°rio
docker exec kafka kafka-topics.sh --create --topic bcc-tcc --bootstrap-server localhost:9092 --partitions 3 --replication-factor 1
```

#### 8. **Erro: "Baseline server not responding"**
```bash
# Verificar se servidor est√° rodando
ps aux | grep "python main.py --server"

# Se n√£o estiver, iniciar manualmente
python main.py --server --port 5000 &

# Testar conectividade
curl -X POST http://localhost:5000/notify -H "Content-Type: application/json" -d '{"message": "test"}'
```

#### 9. **Erro: "Arquivo de tempos de envio n√£o encontrado"**
```bash
# Limpar logs antigos que podem estar causando confus√£o
./scripts/clear_logs.sh

# Executar teste novamente
python main.py --count 5 --size 100 --only rabbitmq
```

#### 10. **Erro: "Mensagem recebida sem timestamp correspondente"**
```bash
# Este erro indica que o consumidor est√° lendo mensagens antigas
# Limpar logs e executar teste limpo
./scripts/clear_logs.sh
python main.py --count 5 --size 100 --only kafka
```

### Logs de Debug

#### Verificar Logs da Aplica√ß√£o
```bash
# Logs gerais
tail -f logs/application.log

# Logs espec√≠ficos de cada broker
tail -f logs/baseline/benchmark_results.csv
tail -f logs/rabbitmq/benchmark_results.csv
tail -f logs/kafka/benchmark_results.csv
```

#### Verificar Logs do Docker
```bash
# Logs de todos os containers
docker compose logs -f

# Logs de um container espec√≠fico
docker compose logs -f rabbitmq-1
docker compose logs -f kafka
```

### Reset Completo do Ambiente

Se nada funcionar, execute um reset completo:

```bash
# Parar tudo
docker compose down -v
deactivate

# Remover ambiente virtual
rm -rf venv

# Limpar Docker
docker system prune -a

# Reconfigurar tudo
./scripts/setup_dev_environment.sh
source venv/bin/activate
docker compose up -d
```

---

## üìö Documenta√ß√£o T√©cnica

### Arquitetura do Sistema

#### Componentes Principais
1. **Orquestrador**: `main.py` - Ponto de entrada √∫nico
2. **Brokers**: Implementa√ß√µes modulares em `src/brokers/`
3. **Core**: Configura√ß√µes e utilit√°rios em `src/core/`
4. **Orquestra√ß√£o**: L√≥gica de testes em `src/orchestration/`

#### Fluxo de Execu√ß√£o
```
main.py ‚Üí BenchmarkOrchestrator ‚Üí Broker Classes ‚Üí Metrics Collection ‚Üí Logs
```

### Configura√ß√µes T√©cnicas

#### RabbitMQ
- **Vers√£o**: 4.1.1
- **Cluster**: 3 n√≥s com Quorum Queues
- **Portas**: 5672 (AMQP), 15672 (Management)
- **Configura√ß√µes**: Confirma√ß√£o de entrega, mensagens persistentes

#### Apache Kafka
- **Vers√£o**: 4.0 (imagem Docker: `bitnami/kafka:3.6`)
- **Modo**: KRaft (sem Zookeeper)
- **Queue Mode**: Simula√ß√£o de KIP-932
- **Portas**: 9092 (Broker), 9000 (Kafdrop)
- **Nota**: A tag `3.6` do Bitnami garante reprodutibilidade e suporta KRaft. A numera√ß√£o do Bitnami n√£o corresponde exatamente √† vers√£o do Kafka. Para Kafka 4.0 exato, verifique tags dispon√≠veis em: https://hub.docker.com/r/bitnami/kafka/tags

#### Baseline HTTP
- **Framework**: Flask
- **Porta**: 5000 (configur√°vel)
- **Processamento**: 1ms simulado por requisi√ß√£o

### M√©tricas Coletadas

#### Lat√™ncia
- **T1**: Timestamp ap√≥s confirma√ß√£o do broker
- **T2**: Timestamp ap√≥s processamento
- **Lat√™ncia**: T2 - T1

#### Throughput
- **C√°lculo**: Mensagens processadas / Tempo total
- **Unidade**: Mensagens por segundo

#### Recursos
- **CPU**: Percentual de uso
- **Mem√≥ria**: Uso em MB
- **Coleta**: A cada 5 segundos durante testes

### Valida√ß√£o Cient√≠fica

#### Reprodutibilidade
- **Ambiente**: Docker containerizado
- **Vers√µes**: Fixas e documentadas
- **Configura√ß√µes**: Padronizadas e versionadas

#### M√©tricas
- **Precis√£o**: Timestamps com precis√£o de microssegundos
- **Consist√™ncia**: Mesmo ambiente para todos os testes
- **Comparabilidade**: Mesmas condi√ß√µes para todos os brokers

---

## üéØ Conclus√£o

Este sistema de benchmark foi desenvolvido seguindo rigorosos padr√µes acad√™micos para garantir:

1. **Reprodutibilidade**: Qualquer pesquisador pode replicar os resultados
2. **Precis√£o**: M√©tricas coletadas com alta precis√£o
3. **Completude**: Todos os aspectos relevantes s√£o testados
4. **Documenta√ß√£o**: Processo completamente documentado

### Contato e Suporte

Para d√∫vidas sobre a implementa√ß√£o ou an√°lise dos resultados:
- **E-mail**: leonardosfiamoncini@gmail.com